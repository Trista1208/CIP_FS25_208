{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CIP_crawling import crawl_for_links, crawl_for_product_data, data_to_csv\n",
    "from clean_data import clean_data, generate_report, process_data, get_cleaned_data\n",
    "from Vacuum_EDA import eda_default_execution, eda_selective_execution, eda_custom_execution\n",
    "from CIP_analysis import load_old, load_new, inspecting_outputs, onehot_encoding, price_efficiency, feature_rating, price_efficiency_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get product URLs from the search results page\n",
    "urls = crawl_for_links(url=\"https://www.galaxus.ch/en/s2/producttype/robot-vacuum-cleaners-174?take=204\")\n",
    "\n",
    "# Scrape all product data and store it in a dictionary\n",
    "data = crawl_for_product_data(urls[:10])        # [:10] is for testing only. Scraping one product takes ~4 seconds, so scraping ~500 products takes about 40 minutes.\n",
    "\n",
    "# Save the data to a .csv file\n",
    "data_to_csv(data, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part of the script used clean_data.py module to process robot vacuum data.\n",
    "The script imports functions from clean_data.py and executes them to:\n",
    "1. Clean the robot vacuum dataset\n",
    "2. Create a detailed analysis report \n",
    "3. Output files ready for further analysis and plotting\n",
    "\"\"\"\n",
    "\n",
    "print(\"## Data Cleaning\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Method 1: Using the complete pipeline\n",
    "print(\"\\n1. Using process_data() for complete pipeline:\")\n",
    "original_df, cleaned_df, report = process_data(\n",
    "    input_file='robot_vacuums.csv',\n",
    "    output_file='robot_vacuums_cleaned.csv',\n",
    "    report_file='Vacuum robots info summary.txt',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Method 2: Using individual functions step by step\n",
    "print(\"\\n2. Using individual functions step-by-step:\")\n",
    "print(\"Step 1: Cleaning the data\")\n",
    "df_original, df_cleaned = clean_data(\n",
    "    input_file='robot_vacuums.csv',\n",
    "    output_file='robot_vacuums_cleaned.csv'\n",
    ")\n",
    "\n",
    "print(\"\\nStep 2: Creating the report\")\n",
    "report_lines = generate_report(\n",
    "    df_cleaned=df_cleaned,\n",
    "    output_file='Vacuum robots info summary.txt'\n",
    ")\n",
    "\n",
    "# Method 3: Quick access to cleaned data for analysis\n",
    "print(\"\\n3. Quick access using get_cleaned_data():\")\n",
    "quick_df = get_cleaned_data(force_clean=False)\n",
    "print(f\"Shape of quickly accessed data: {quick_df.shape}\")\n",
    "print(f\"Columns: {quick_df.columns[:5]}...\")\n",
    "\n",
    "print(\"\\n## Ready for Data Analysis\")\n",
    "print(\"-\" * 50)\n",
    "print(\"The cleaned data is now ready for analysis!\")\n",
    "print(\"You can now proceed with the Data Analysis section using the following file:\")\n",
    "print(\"- robot_vacuums_cleaned.csv\")\n",
    "print(\"\\nSample code for analysis:\")\n",
    "print(\"df_cleaned = pd.read_csv('robot_vacuums_cleaned.csv')\")\n",
    "print(\"# Perform your analysis here...\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this functions we can make the different variants of evaluation to get a impression of the data\n",
    "\n",
    "# Running the full EDA pipeline with default parameters\n",
    "eda_default_execution()\n",
    "\n",
    "# Specifying custom input, output files and plots directory\n",
    "eda_custom_execution()\n",
    "\n",
    "# Running only specific analysis functions\n",
    "eda_selective_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned CSV file\n",
    "df_cleaned = load_new(new_csv=\"robot_vacuums_cleaned.csv\", print_i=False)\n",
    "\n",
    "# Create one-hot encodings from the features\n",
    "df_onehot = onehot_encoding(df_cleaned, print_i=False)\n",
    "\n",
    "# Calculate the price-efficiency of the products and return the top X products for each category\n",
    "price_efficiency(df_onehot, top=5)\n",
    "\n",
    "# Analyze the influence of features on product ratings and display those with the lowest p-values\n",
    "feature_rating(df_onehot)\n",
    "\n",
    "# Price \n",
    "price_efficiency_features(df_onehot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".CIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
